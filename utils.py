import torch
import math
import struct
import comfy.checkpoint_pickle
import safetensors.torch
import numpy as np
from PIL import Image
import logging
import itertools
from torch.nn.functional import interpolate
from einops import rearrange
from comfy.cli_args import args
import io
from io import BytesIO
import logging
import gc
from safetensors.torch import load_file
import tempfile
import shutil
import os
from pathlib import Path
import struct
import json
import safetensors.torch
import string
import subprocess
import time
import sys
import stat
MMAP_TORCH_FILES = args.mmap_torch_files
DISABLE_MMAP = args.disable_mmap

ALWAYS_SAFE_LOAD = False

def load_torch_file(ckpt, safe_load=False, device=None, return_metadata=False, use_ram_cache=True):
    """
    åŠ è½½ torch æ–‡ä»¶ï¼Œæ”¯æŒä»å†…å­˜ä¸­åŠ è½½ä»¥ä¼˜åŒ–æœºæ¢°ç¡¬ç›˜æ€§èƒ½

    Args:
        ckpt: æ–‡ä»¶è·¯å¾„
        safe_load: æ˜¯å¦å®‰å…¨åŠ è½½
        device: ç›®æ ‡è®¾å¤‡
        return_metadata: æ˜¯å¦è¿”å›å…ƒæ•°æ®
        use_ram_cache: æ˜¯å¦å…ˆå¤åˆ¶åˆ°å†…å­˜å†åŠ è½½ï¼ˆé’ˆå¯¹ safetensorsï¼‰
    """
    if device is None:
        device = torch.device("cpu")

    metadata = None

    if ckpt.lower().endswith(".safetensors") or ckpt.lower().endswith(".sft"):
        return _load_safetensors(ckpt, device, return_metadata, use_ram_cache)
    else:
        return _load_torch_checkpoint(ckpt, device, return_metadata, safe_load)


def _load_safetensors(ckpt, device, return_metadata, use_ram_cache):
    """åŠ è½½ safetensors æ–‡ä»¶ï¼Œå¯é€‰æ‹©ä»å†…å­˜åŠ è½½"""

    file_size = os.path.getsize(ckpt)
    logging.info(f"Safetensors æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")

    # å¦‚æœæ–‡ä»¶è¾ƒå°æˆ–ç¦ç”¨ RAM ç¼“å­˜ï¼Œç›´æ¥åŠ è½½
    if not use_ram_cache or file_size < 100 * 1024 * 1024:  # å°äº 100MB ç›´æ¥åŠ è½½
        return _load_safetensors_direct(ckpt, device, return_metadata)

    # æ–‡ä»¶è¾ƒå¤§ï¼Œå…ˆå¤åˆ¶åˆ°å†…å­˜å†åŠ è½½
    logging.info("å°†æ–‡ä»¶å¤åˆ¶åˆ°å†…å­˜...")

    z_path = Path("Z:/")
    target_path = z_path / Path(ckpt).name

    # æ¸…ç©º Z ç›˜å†…å®¹
    if z_path.exists() and z_path.is_dir():
        for item in z_path.iterdir():
            try:
                if item.is_dir():
                    shutil.rmtree(item)
                else:
                    item.unlink()
            except Exception as e:
                logging.warning(f"åˆ é™¤ Z ç›˜å†…å®¹å¤±è´¥: {item}, é”™è¯¯: {e}")

    # å¤åˆ¶æ–‡ä»¶åˆ° Z ç›˜
    shutil.copy2(ckpt, target_path)
    logging.info(f"ğŸ“‚ æ–‡ä»¶å·²å¤åˆ¶åˆ° Z ç›˜: {target_path}")

    return _load_safetensors_direct(target_path, device, return_metadata)





def _load_safetensors_direct(ckpt, device, return_metadata):
    """ç›´æ¥åŠ è½½ safetensors æ–‡ä»¶"""
    try:
        with safetensors.safe_open(ckpt, framework="pt", device=device.type) as f:
            sd = {}
            for k in f.keys():
                tensor = f.get_tensor(k)
                # ç¡®ä¿å¼ é‡åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
                if tensor.device != device:
                    tensor = tensor.to(device=device, copy=True)
                sd[k] = tensor

            metadata = f.metadata() if return_metadata else None
            return (sd, metadata) if return_metadata else sd

    except Exception as e:
        if len(e.args) > 0:
            message = e.args[0]
            if "HeaderTooLarge" in message:
                raise ValueError(
                    f"{message}\n\nFile path: {ckpt}\n\n"
                    "The safetensors file is corrupt or invalid. "
                    "Make sure this is actually a safetensors file and not a ckpt or pt or other filetype."
                )
            if "MetadataIncompleteBuffer" in message:
                raise ValueError(
                    f"{message}\n\nFile path: {ckpt}\n\n"
                    "The safetensors file is corrupt/incomplete. "
                    "Check the file size and make sure you have copied/downloaded it correctly."
                )
        raise e


def _load_torch_checkpoint(ckpt, device, return_metadata, safe_load):
    """åŠ è½½ä¼ ç»Ÿ torch checkpoint æ–‡ä»¶åˆ°å†…å­˜å†è¯»å–"""
    torch_args = {}

    logging.info(f"å°† {ckpt} æ–‡ä»¶åŠ è½½åˆ°å†…å­˜ä¸­...")
    try:
        with open(ckpt, "rb") as f:
            file_bytes = f.read()
    except Exception as e:
        logging.error(f"è¯»å–æ–‡ä»¶ {ckpt} å¤±è´¥: {e}")
        raise

    buffer = BytesIO(file_bytes)

    if safe_load:
        logging.info("ä½¿ç”¨å®‰å…¨åŠ è½½æ¨¡å¼...")
        pl_sd = torch.load(buffer, map_location=device, weights_only=True, **torch_args)
    else:
        logging.warning(f"WARNING: loading {ckpt} unsafely, upgrade your pytorch to 2.4 or newer")
        pl_sd = torch.load(buffer, map_location=device)

    # è§£æçŠ¶æ€å­—å…¸
    if "state_dict" in pl_sd:
        sd = pl_sd["state_dict"]
    else:
        if len(pl_sd) == 1:
            key = list(pl_sd.keys())[0]
            sd = pl_sd[key]
            if not isinstance(sd, dict):
                sd = pl_sd
        else:
            sd = pl_sd

    metadata = None
    return (sd, metadata) if return_metadata else sd
